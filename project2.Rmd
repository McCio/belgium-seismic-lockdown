
```{r libraries, include=FALSE}
knitr::opts_chunk$set(warning = F, message = F)
library(stringi) # %s+%
library(lubridate) # floor_date
library(xts) # zoo
library(fpp) # auto.arima
library(gridExtra) # for gg-plotting multiple plots
library(tidyverse) # map_df, read_csv, group_by, summarize
library(tsbox) # https://cran.r-project.org/web/packages/tsbox/vignettes/tsbox.html
print_dec <- function(x, decimals=2) trimws(format(round(x, decimals), nsmall=decimals))

setwd("/media/data/Documents/Uni/spatiotemp/villalobos/project/")
```


```{r import dataset, include=FALSE}
# UCCS
domain <- c(-350000,350000); pattern <- "UCCS.*\\.csv"; name <- "UCCS"; description <- "Uccle, Bruxelles"
# MEMS
# domain <- c(-7200,7200); pattern <- "MEM.*.csv"; name <- "MEM"; description <- "Membach"
seis <-
  list.files(path="csv/", pattern=pattern) %>%
  map_df(~read_csv("csv/" %s+% .))
```



# Data preparation
```{r dataset description, echo=FALSE}
long_description <- description %s+% " (" %s+% name %s+% " station)"
long_description
"Domain values: " %s+% domain[1] %s+% " to " %s+% domain[2] %s+% " nm"
"Data from " %s+% format.POSIXct(min(seis$utc_second), "%Y-%m-%d %H:%M:%S") %s+% " to " %s+% format.POSIXct(max(seis$utc_second), "%Y-%m-%d %H:%M:%S")
```

```{r cleanup, echo=FALSE}
out_domain <- (seis$min < domain[1] | seis$max > domain[2])
invalid_values <- (seis$min == -1 & seis$max == 1) | (seis$min == 0 & seis$max == 0) | out_domain
"Removing " %s+% sum(out_domain) %s+% " values out of domain, " %s+% (sum(invalid_values) - sum(out_domain)) %s+% " explicit NA"
seis <-
  seis %>%
  mutate(min=replace(min, invalid_values, NA), max=replace(max, invalid_values, NA)) %>%
  drop_na()
# %>% mutate(belgian_second=with_tz(utc_second, "Europe/Brussels"))
remove(out_domain, invalid_values) # free ~350 Mb from RAM
```

```{r missing values analysis}
seis.complete <- seis %>% complete(utc_second=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = as.difftime("0:0:1")))
seis.first.second <- min(seis$utc_second)
seis.missing.ids <- which(is.na(seis.complete$min))

seis.present <- length(seis$utc_second)
seis.total <- length(seis.complete$utc_second)
seis.missing <- seis.total - seis.present
seis.present %s+% " present values, " %s+% seis.missing %s+% " missing points (" %s+% print_dec(seis.present / seis.total * 100, 2) %s+% "% / " %s+% print_dec(seis.missing / seis.total * 100, 2) %s+% "%)"

block_start <- NULL
block_end <- NULL
blocks <- data.frame(start=integer(), end=integer())
for (i in 1:length(seis.missing.ids)) {
  if (is.null(block_start)) {
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  } else if ((block_end + 1) == seis.missing.ids[i]) {
    block_end <- seis.missing.ids[i]
  } else {
    blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  }
}
blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
blocks$interval <- seconds(blocks$end - blocks$start + 1)
blocks$start <- seis.first.second + seconds(blocks$start)
blocks$end <- seis.first.second + seconds(blocks$end)
plot(blocks$start, blocks$interval,
     col=ifelse(blocks$interval<3600, "darkgreen", "darkred"),
     main="Consecutive seconds of missing values",
     ylab="Seconds", xlab="Interval start",
     xaxt="n", xlim=c(min(seis$utc_second), max(seis$utc_second))
     )
axis.POSIXct(1, at=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = "1 month"), format="%m-%y", cex=0.8)
abline(h=3600, col="green", lty="dotted")
legend("topleft", legend=c("interval >= 1h", "interval < 1h", "1h"), col=c("darkred", "darkgreen", "green"), lty=c(NA,NA,3), pch=c(1,1,NA),cex=0.9, bty="n")
text(x=blocks$start[which(blocks$interval > 3600)], y=blocks$interval[which(blocks$interval > 3600)], labels = paste0(blocks$start[which(blocks$interval > 3600)], " - ", blocks$end[which(blocks$interval > 3600)]), cex=0.9, pos=4)
remove(seis.complete, seis.missing.ids)
```


```{r gc_post_missing_analysis, include=FALSE}
gc()
```

```{r group by hour, include=FALSE}
bruxelles <- function(d) with_tz(d, "Europe/Brussels")
force_bruxelles <- function(d) force_tz(d, "Europe/Brussels")

seis.h <- 
  seis %>%
  # mutate(utc_hour=as_datetime(date(utc_second)) + hour(utc_second) * 3600) %>% # this forces the hour to represent bruxelles local time in utc. tz-ed time is normally evaluated in utc by ts-related functions
  group_by(utc_hour=floor_date(force_tz(bruxelles(utc_second), "UTC"), "1 hour")) %>%
  summarize(mean_movement_s=mean(max-min)) # %>%
#  complete(utc_hour=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = as.difftime("1:0:0")))

seis.before <- 
  seis.h[which(is.na(force_bruxelles(seis.h$utc_hour) + hours(1))), ] %>%
  mutate(utc_hour=utc_hour + hours(1))

seis.after <- 
  seis.h[which(is.na(force_bruxelles(seis.h$utc_hour) - hours(1))), ] %>%
  mutate(utc_hour=utc_hour - hours(1))

seis.dst.fix <-
  merge(seis.before, seis.after, all=T) %>%
  group_by(utc_hour=utc_hour) %>%
  summarize(mean_movement_s=mean(mean_movement_s))

seis.h <- merge(seis.h, seis.dst.fix, all=T)
remove(seis.after, seis.before, seis.dst.fix)
gc()
```



```{r missing values hour analysis}
seis.complete <- seis.h %>% complete(utc_hour=seq.POSIXt(from=min(seis.h$utc_hour), to=max(seis.h$utc_hour), by = as.difftime("1:0:0")))
seis.first.second <- min(seis$utc_second)
seis.missing.ids <- which(is.na(seis.complete$mean_movement_s))

seis.present <- length(seis.h$utc_hour)
seis.total <- length(seis.complete$utc_hour)
seis.missing <- seis.total - seis.present
seis.present %s+% " present values, " %s+% seis.missing %s+% " missing points (" %s+% print_dec(seis.present / seis.total * 100, 2) %s+% "% / " %s+% print_dec(seis.missing / seis.total * 100, 2) %s+% "%)"

block_start <- NULL
block_end <- NULL
blocks <- data.frame(start=integer(), end=integer())
for (i in 1:length(seis.missing.ids)) {
  if (is.null(block_start)) {
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  } else if ((block_end + 1) == seis.missing.ids[i]) {
    block_end <- seis.missing.ids[i]
  } else {
    blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  }
}
blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
blocks$interval <- hours(blocks$end - blocks$start + 1)
blocks$start <- seis.first.second + hours(blocks$start)
blocks$end <- seis.first.second + hours(blocks$end)
plot(c(blocks$start, blocks$end), rep(hour(blocks$interval), 2),
     col=ifelse(blocks$interval<3600, "darkgreen", "darkred"),
     main="Consecutive hours of missing values",
     ylab="Hours", xlab="Interval start",
     type="l", lwd=10,
     xaxt="n", xlim=c(min(seis$utc_second), max(seis$utc_second))
     )
axis.POSIXct(1, at=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = "1 month"), format="%m-%y", cex=0.8)
text(x=blocks$start, y=hour(blocks$interval), labels = paste0(format(blocks$start, "%y-%m-%d %H:%M")), cex=0.9, pos=2)
text(x=blocks$end, y=hour(blocks$interval), labels = paste0(format(blocks$end, "%y-%m-%d %H:%M")), cex=0.9, pos=4)
text(x=blocks$start + blocks$interval/2, y=hour(blocks$interval), labels = paste0(hour(blocks$interval), "H"), cex=0.9, pos=3)
remove(seis.complete, seis.missing.ids)

```

```{r gc_post_missing_analysis_bru, include=FALSE}
gc()
```

```{r build_ts function, include=FALSE}
build_ts <- function(dset, periods=NULL, start=NULL, end=NULL, force_ms=T) {
  dset.ts <- ts_zoo(dset)
  if (!is.null(start) | !is.null(end)) {
    dset.ts <- ts_span(dset.ts, start=start, end=end)
  }
  dset.ts <- ts_regular(dset.ts)
  if (is.null(periods)) {
    return(dset.ts)
  }
  if (is.vector(periods) & length(periods) == 1) {
    periods <- periods[1]
  }
  if (is.integer(periods)){
    if (force_ms) {
      periods <- c(periods)
    } else {
      frequency(dset.ts) <- periods
      return(dset.ts)
    }
  }
  return(msts(dset.ts, periods))
}
```


```{r}
seis.h.start <- as_datetime('2018-10-29T00:00:00')
seis.h.end <- as_datetime('2020-03-01T00:00:00')
seasonality.period <- 168
seis.h.ts <- build_ts(seis.h, periods = c(seasonality.period), start = seis.h.start, end = seis.h.end, force_ms = T)
autoplot(seis.h.ts, main = "Hourly seismic movement", xlab = "Weeks", ylab = "mean movement (nm)")
hist(seis.h.ts)
autoplot(acf(seis.h.ts, na.action=na.pass, plot=F))
autoplot(pacf(seis.h.ts, na.action=na.pass, plot=F))

```
Once notice the composition is additive (the fluctuations does not seem to grow with the trend)
```{r}
dec.addi <- decompose(na.aggregate(seis.h.ts, floor))
autoplot(dec.addi)
dec.multi <- decompose(log(na.aggregate(seis.h.ts, floor)))
autoplot(dec.multi)
autoplot(acf(dec.addi$random, na.action=na.omit, plot=F))
autoplot(acf(dec.multi$random, na.action=na.omit, plot=F))
autoplot(pacf(dec.addi$random, na.action=na.omit, plot=F))
autoplot(pacf(dec.multi$random, na.action=na.omit, plot=F))
```

We now extract the trend using a linear filter with smoothing parameter $p$ equal to 180 (almost half a year):

```{r}
p <- floor(seasonality.period/2)
weights <- rep(1/(2*p+1), times=2*p+1)
trend <- stats::filter(na.aggregate(seis.h.ts, floor), sides=2, filter = weights)
```


```{r show_overlap_and_diff, include=FALSE}
show_overlap_and_diff <- function(base, compare, base.desc, compare.desc, xlab, overlap.ylab, diff.title, diff.ylab, diff.ylab.sec, diff.ylab.sec.accuracy=.1) {
  overlap_plot <-
    autoplot(compare, xlab=xlab, ylab=overlap.ylab) +
      geom_line(aes(y=base, col="red"), show.legend = F)
  span <- max(compare, base, na.rm = T) - min(compare, base, na.rm = T)
  diff <- compare-base
  accu.lims <- diff.ylab.sec.accuracy / 100 * span * c(-3,3)

  diff_plot <-
    autoplot(diff, ylab = paste0("Difference (", diff.ylab, ")"), xlab = xlab) +
      expand_limits(y=accu.lims) +
      labs(title = diff.title, subtitle = paste0(base.desc, " - ", compare.desc)) +
      scale_y_continuous(sec.axis = sec_axis(~./span, name=paste0("Difference (", diff.ylab.sec, ")"), labels = scales::percent_format(accuracy = diff.ylab.sec.accuracy))) +
      geom_hline(yintercept=mean(diff, na.rm=T), linetype="dashed", color = "red")
  return(list(overlap_plot, diff_plot))
}
```


And they match:
```{r}
plots <- show_overlap_and_diff(
  dec.addi$trend, trend, xlab="Weeks",
  base.desc = "additive decomposition",
  compare.desc = paste0("linear filtered trend with p=", p),
  overlap.ylab = "Trend (nm)",
  diff.title = "Difference between trends",
  diff.ylab = "nm", diff.ylab.sec="% over trend span"
)
plots[[1]]
plots[[2]]

```

Then we use a filter able also to capture some seasonal effect so we will be able to find the residuals. We are going to choose $f=365$ so to have the moving average from the first day of the year to the last one and then shifted from the second day of the year to the first one of the following year and so, this is because we believe to have an yearly seasonality.

```{r}
f <- seasonality.period
weights.s <- c(0.5, rep(1,f-1), 0.5)/f
trend.s <- stats::filter(na.aggregate(seis.h.ts, floor), side=2, filter=weights.s)

plots <- show_overlap_and_diff(
  dec.addi$trend, trend.s, xlab="Weeks",
  base.desc = "additive decomposition",
  compare.desc = paste0("shift-filtered trend with f=", f),
  overlap.ylab = "Trend (nm)",
  diff.title = "Difference between trends",
  diff.ylab = "nm", diff.ylab.sec="% over trend span",
  diff.ylab.sec.accuracy = .01
)
plots[[1]]
plots[[2]]

```

and they match (with some error of course) with the ones found with the decompose function.

Finally we want to prove we can retrieve seasonality, in order to do so we can compute the average seasonality starting from the detrended series: to do so we put the time series into a matrix and we transform this matrix so each column contains elements of the same period and finally, we compute the mean of each column. We will check this with the element figure of the object decomposition i.e. the estimated seasonal figure not repeated for all the time series. 

```{r}
detrended <- na.aggregate(seis.h.ts, floor)-trend.s
detrended <- window(detrended, end = c(end(detrended)[1], seasonality.period), extend=T)
matrix <- t(matrix(data = detrended, nrow = seasonality.period))
seasonality.figure <- as.ts(colMeans(matrix, na.rm = T))
seasonality <- rep(seasonality.figure, length(detrended)/length(seasonality.figure))[1:length(trend.s)]
```

and they almost match: 

```{r}

plots <- show_overlap_and_diff(
  dec.addi$figure, seasonality.figure, xlab="Hours",
  base.desc = "additive decomposition",
  compare.desc = paste0("mean-over-period after removal of shift-filtered trend with f=", f),
  overlap.ylab = "Seasonality (nm)",
  diff.title = paste0("Difference between seasonalities (f=", seasonality.period, ")"),
  diff.ylab = "nm", diff.ylab.sec="% over seasonality span",
  diff.ylab.sec.accuracy = .01
)
plots[[1]]
plots[[2]]

# difference is maybe given by na.aggregate used in decompose, while na.rm=T in manual seasonality?
```

```{r}
residuals <- na.aggregate(seis.h.ts, floor) - trend.s - seasonality

plots <- show_overlap_and_diff(
  dec.addi$random, residuals, xlab="Weeks",
  base.desc = "additive decomposition",
  compare.desc = paste0("mean-over-period after removal of shift-filtered trend with f=", f),
  overlap.ylab = "Residuals (nm)",
  diff.title = paste0("Difference between residuals (f=", seasonality.period, ")"),
  diff.ylab = "nm", diff.ylab.sec="% over residuals span",
  diff.ylab.sec.accuracy = .01
)
plots[[1]]
plots[[2]]

```

In fact we are able to reconstruct the original series, with of course some missing value at the beginning and at the end because of the methods applied previously:

```{r}
ts <- residuals+trend.s+seasonality

plots <- show_overlap_and_diff(
  seis.h.ts, ts, xlab="Weeks",
  base.desc = "original series",
  compare.desc = "reconstructed series",
  overlap.ylab = "Mean hourly movement (nm)",
  diff.title = "Difference between ts",
  diff.ylab = "nm", diff.ylab.sec="% over ts span",
  diff.ylab.sec.accuracy = .01
)
plots[[1]]
plots[[2]]

plots <- show_overlap_and_diff(
  seis.h.ts, dec.addi$trend+dec.addi$seasonal+dec.addi$random, xlab="Weeks",
  base.desc = "original series",
  compare.desc = "reconstructed series",
  overlap.ylab = "Mean hourly movement (nm)",
  diff.title = "Difference between ts",
  diff.ylab = "nm", diff.ylab.sec="% over ts span",
  diff.ylab.sec.accuracy = .01
)
plots[[1]]
plots[[2]]

```













```{r residuals cf arima, fig.height=960, fig.width=960, fig.path="/tmp/"}
residuals.acf <- autoplot(acf(residuals, na.action = na.pass, plot=F))
residuals.pacf <- autoplot(pacf(residuals, na.action = na.pass, plot=F))
plot_grid(residuals.acf, residuals.pacf, labels = "AUTO", nrow=2)

seis.h.ts.ar <- Arima(seis.h.ts, c(1,0,0))
tsdiag(seis.h.ts.ar)
library(cowplot)
install.packages("cowplot")
```







```{r}
seis.h.start <- with_tz(as_datetime('2018-11-01T00:00:00'), "Europe/Brussels")
seis.h.end <- with_tz(as_datetime('2020-03-01T00:00:00'), "Europe/Brussels")
seis.h.msts <- na.aggregate(build_ts(seis.h, periods = c(24, 168), start = seis.h.start, end = seis.h.end, force_ms = T))
seis.h.msts %>% mstl() %>% autoplot() + xlab("Week")
seis.h.msts.mstl <- seis.h.msts %>% mstl()
plot(seis.h.msts.mstl[,2], main="trend")
lines(trend.s, col="red")
plot(rowSums(seis.h.msts.mstl[,3:4]), main="seasonality",type="l")
lines(seasonality, col="red")
plot(residuals,  main="residuals")
lines(seis.h.msts.mstl[,5], col="red")
autoplot(seis.h.msts.mstl[,5])
acf(seis.h.msts.mstl[,5], na.action = na.omit)
bptests <- c()
for (i in 1:10)
  bptests<- c(bptests, Box.test(seis.h.msts.mstl[,5], lag = i, fitdf = 0, type = "Box-Pierce")$p.value)
plot(bptests, ylim = c(0,1))
abline(h=0.05,col="blue",lty="dotted")

```