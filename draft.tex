\documentclass[12pt]{article}

% BY MINE REPORTS
\usepackage{fancyhdr}
\usepackage{lastpage} % last page ref
\usepackage{array}
\usepackage[table]{xcolor}
\usepackage{scrextend}
\usepackage{enumitem}
\usepackage{caption} % for image/tables/... captions
\usepackage{fancyvrb} % for centered verbatim
%\usepackage{hyperref} % for links in refs
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[round, sort, numbers]{natbib}
\bibliographystyle{unsrtnat}
% /BY MINE REPORTS

% BY VARIN
\usepackage[sc]{mathpazo}
\usepackage{amsthm,amsmath,amssymb}
\usepackage{titlesec}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{a4paper,verbose,tmargin=2.5cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
 breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
 {hyperref}
\hypersetup{
 pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
% /BY VARIN

% BY MINE REPORTS
\renewcommand{\labelenumii}{\theenumi\theenumii.}
\renewcommand{\theenumii}{.\arabic{enumii}}
\renewcommand{\labelenumiii}{\theenumi\theenumii\theenumiii.}
\renewcommand{\theenumiii}{.\arabic{enumiii}}

\newtheorem*{theorem}{Theorem}
\newtheorem*{proposition}{Proposition}

\pagestyle{fancy}
\fancyhf{}
% /BY MINE REPORTS

% FOR KNITR CHILD
%\usepackage[]{graphicx} %% used before
\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
	\ifdim\Gin@nat@width>\linewidth
	\linewidth
	\else
	\Gin@nat@width
	\fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
	\def\at@end@of@kframe{}%
	\ifinner\ifhmode%
	\def\at@end@of@kframe{\end{minipage}}%
\begin{minipage}{\columnwidth}%
	\fi\fi%
	\def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
		\colorbox{shadecolor}{##1}\hskip-\fboxsep
		% There is no \\@totalrightmargin, so:
		\hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
	\MakeFramed {\advance\hsize-\width
		\@totalleftmargin\z@ \linewidth\hsize
		\@setminipage}}%
{\par\unskip\endMakeFramed%
	\at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% / FOR KNITR CHILD

\renewcommand{\theequation}{\roman{equation}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\p}{p}
\DeclareMathOperator*{\cov}{cov}
\DeclareMathOperator*{\var}{var}
\DeclareMathOperator*{\diag}{diag}
\DeclareMathOperator{\Bernoulli}{Bernoulli}
\DeclareMathOperator{\given}{\vert}
\newcommand*\mean[1]{\overline{#1}}
\DeclareMathOperator*{\simf}{sim}

\title{Seismic Time Series Analysis\\Statistics for Spatio-Temporal Data\\\textit{-- project draft --}}
\author{Marco Ciotola, 848222}
\date{\today}


\begin{document}
\pagenumbering{gobble}
\maketitle
\begin{figure}[t!]
	\begin{center}
		\includegraphics[width=100px]{ca_foscari_logo.png}
	\end{center}
\end{figure}
\vfill Prof. Isadora Antoniano Villalobos - CM0477
\hfill A.Y. 2019/2020
\newpage
\tableofcontents \clearpage
\fancyfoot[RO,LE]{Page \thepage \hspace{1pt} of \pageref{LastPage}}
\pagenumbering{arabic}
% /BY MINE REPORTS

% BY VARIN
%\setlength{\parindent}{0pt}
% /BY VARIN


\section{Introduction}

\subsubsection{Motivation and objective}
Thanks to the recent COVID-19 outbreak worldwide, we currently have data about many different phoenomena from periods with standard human activity, and from a period with reduced human activity.

Inspired by an article published during the initial phases of the Belgium-wide lockdown \cite{NatureCoronavirusSeismic}, we want to assess whether the lockdown period can be correlated with a visible change in seismic activity.
It is important to notice that some industrial events, such as mine explosions, are already mapped by seismologic institutions since they interfere with seismic surveys \cite{OtherSeismicEvents}. Such events are sometimes comparable with natural seismic events, depending on the distance from the seismograph.

The correct estimation of a background noise, correlated or not with human activity, could help institutions to better isolate less prominent earthquakes and similar events from the seismic data. This could result in better understanding of the frequency of earthquakes and by studying their more-precise evolution over time.

\subsubsection{Data source and description}
The Royal Observatory of Belgium (ROB) gathers and publishes \cite{RoyalDataPolicy,Data20200402} data about vertical ground displacement from 9 stations through the country, linking them to seismic events whenever possible \cite{DataEvents20200402}. They also offer a data visualization tool for the same data \cite{DataVisualization20200402}.

The vertical ground displacement is represented by the minimum and maximum displacements of the ground in the vertical axis, with $nm$ as unit of measure. This can easily be transformed to total ground displacement for that second by their difference.
For each day, a pair per second is available (86400 per day, around 30 million per year).

Out of the 9 stations, the following 6 have interesting positions, related to possible correlations with human activity:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item \textbf{Uccle}, \textbf{Sart-Tilman}, and \textbf{Ében-Émael} are near a city (Bruxelles, Liege, and Maastricht).
	\item \textbf{Ostenda} This station is near the city of Ostenda, that borders with the sea.
	\item \textbf{Membach} and \textbf{Dourbes} are near a natural park.
\end{itemize}

Data collected from near a city and from near a natural park could be selected, in order to compare possible seasonality results and differences from before and after the lockdown. %Also data from \textbf{Ostenda} station could be interesting, given the possible sea influence.
Considering these factors, we selected the \textbf{Uccle} and \textbf{Membach} stations.

It is important to notice that the daily data in each file refers to the UTC time instead of the local Europe/Brussels time, an optimal choice to publish data in a machine-readable way, even if this could cause some issues while interpreting the results.

\subsection{Data cleanup and transformation}\label{sec:cleanup-transform}
\subsubsection{Data gathering and cleanup}
The data is provided in CSV format, one file per day, with only two columns related to the min-max pair \cite{Data20200402} and no column related to time. This causes two problems:
\begin{enumerate}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item Before merging different days, we need to add a column with the complete datetime for each row
	\item Days with some \texttt{NA} values cannot skip rows, so we will find placeholder values that indicate them $(\min, \max) \in \{(0,0), (-1,1)\}$
\end{enumerate}

Data from each station have different domains, as distinct equipment can register a specific amplitude of the seismic movements. In fact, we found some values outside the domains, transformed in \texttt{NA}.

In particular, we find that out of $\approx50$ million seconds, from 27-10-2018 to 28-05-2020, only 0.67\% (Uccle) and 0.37\% (Membach) have invalid values. We will see later how they are distributed for each station.

% Uccle, Bruxelles (UCCS station)
% Domain values: -350000 to 350000 nm
% Data from 2018-10-27 00:00:00 to 2020-05-29 00:12:07
% Removing 7 values out of domain, 28169 explicit NA
% 49779920 present values, 334345 missing points ( 99.33 % / 0.67 % )

% Membach (MEM station)
% Domain values: -7200 to 7200 nm
% Data from 2018-10-27 00:00:00 to 2020-05-29 00:09:55
% Removing 8 values out of domain, 7018 explicit NA
% 49929756 present values, 184421 missing points ( 99.63 % / 0.37 % )

\subsubsection{Data aggregation and initial transformation}
Since we are not interested in a second-precise analysis, and it would be computationally expensive to deal with the whole dataset, we aggregate data by hour. The aggregation will result in around 14 thousand points, that can still be captured by interpretable models.

While performing this operation, we should consider the correct time-zone: any seasonal analysis dealing with UTC data would be out of phase between the half-year when Belgium follows the UTC+01 timezone, and the half-year when it follows the UTC+02 timezone. With the help of the \texttt{lubridate} R package we converted to the actual timezones, and then we kept the actual objects without being timezone explicit, because all the methods we use are smart enough to work on the UTC conversion of datetimes. This transformation made it possible to have, for example, the time 6:00 in the timeseries to represent the local time in Belgium (\textit{Europe/Bruxelles}), without being influenced by the actual time-zone on that specific day.

The aggregation was performed considering the mean ground displacement, for the following reasons:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item When an hour contains some missing seconds, these do not heavily affect the aggregation result, in contrast with summing the differences
	\item Seismic events, such as quakes and mine explosions, normally last some minutes at most, and will affect the result only slightly, as opposed to the hourly maximum
	\item Usually, maximum value aggregation does not follow the Normal distribution, while some models that we are going to use assume the data follow a Normal distribution
\end{itemize}

\section{Analysis and decomposition}
\subsubsection{Missing values analysis}

% Uccle, Bruxelles (UCCS station)
% Domain values: -350000 to 350000 nm
% Data from 2018-10-27 00:00:00 to 2020-05-29 00:12:07
% Removing 7 values out of domain, 28169 explicit NA
% 49779920 present values, 334345 missing points ( 99.33 % / 0.67 % )
% 13831 present values, 90 missing points (99.35% / 0.65%)

% Membach (MEM station)
% Domain values: -7200 to 7200 nm
% Data from 2018-10-27 00:00:00 to 2020-05-29 00:09:55
% Removing 8 values out of domain, 7018 explicit NA
% 49929756 present values, 184421 missing points ( 99.63 % / 0.37 % )
% 13872 present values, 49 missing points (99.65% / 0.35%)

After aggregating by hour, the percentages of missing values remain quite stable. As can be seen from \figurename{s} \ref{missing-values-seconds:uccs} and \ref{missing-values-seconds:mems}, missing values at both stations are grouped in a few consecutive periods.
To deal with them when R methods need complete timeseries, we define different completion strategies, depending on the seasonality, using the R function \texttt{na.aggregate}.

In particular, after a visual analysis of the decomposition results, we can suppose the 90 hours gap from the Uccle station is related to some changes to the seismic equipment, that resulted in slightly more precise measurements.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.uccs_files/figure-latex/missing values hour analysis-1.pdf}
		\caption{Uccle station}
		\label{missing-values-seconds:uccs}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.mems_files/figure-latex/missing values hour analysis-1.pdf}
		\caption{Membach station}
		\label{missing-values-seconds:mems}
	\end{subfigure}
	\caption{Missing values representation}
	\label{missing-values-seconds}
\end{figure}

\subsubsection{Seasonality assumptions}
The already cited article \cite{NatureCoronavirusSeismic} suggests the existence of a weekly seasonality. Looking at the data it seems confirmed, in addition to a daily seasonality.

Since our main focus is on the seasonalities themselves, we aim to prevent assumptions based on this objective. In other words, we want to avoid searching for correlation with human activity while imposing human-based seasonality periods. Thus, we will use an analytical method to extract seasonalities that the data itself suggests to us. Still, we recognize that the already performed transformations impose an human-based time alteration to the data itself (Section \ref{sec:cleanup-transform}).

The method we are going to apply is based on the Fourier Transform, and generates a \textit{periodgram} highlighting the most interesting frequencies that might correspond to a seasonality component.
Applying the FT for any frequency, we transform our 1-dimensional data into a 2-dimensional data mapped around a circle. Then, we can sum all the resulting vectors (that are our new data points) to obtain a vector for each frequency, whose absolute value represents the power level of the same frequency. An high power level represents a significant periodicity on that frequency in our original data.

A common operation to increase the difference between significant and non-significant periodicities is to apply a MA smoothing filter with a smaller window than the interesting ones. We will use such a filter with $f=2$.

On this note we must specify that, when a significant periodicity is found, it influences smaller periodicities given by $f*\{2,3,\dots\}$ the significant frequency. Also, if any periodicity is found that is longer than the original dataset, it must be considered as simple chance, rather than serendipity.

Since we apply this method on a dataset indexed by seconds, the transformation of the frequency $f$ into hourly periodicity $p$ is obtained by $p=(1/f)/3600$.
We can analyse the resulting periodgrams for Uccle and Membach stations in \figurename{s} \ref{fig:periodgram:uccs} and \ref{fig:periodgram:mems}.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.uccs_files/figure-latex/periodgram-1"}
		\caption{Uccle station}
		\label{fig:periodgram:uccs}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.mems_files/figure-latex/periodgram-1"}
		\caption{Membach station}
		\label{fig:periodgram:mems}
	\end{subfigure}
	\caption{Periodgram results}
	\label{fig:periodgram}
\end{figure}

Both highlight multiple 24-hour periodicities. This is given by approximation factors, since we round the divisions result to the nearest natural number. It also highlights that using a single 24-hour seasonality could leave some information on the remaining components. Still, in both stations it is the most significant periodicity.

Both stations highlight a significant 168-hour (1-week) periodicity, that also confirms our initial assumptions.

Both stations show a possibly significant 12-hour seasonality, but since it corresponds to double the frequency of the 24-hour seasonality, we can safely ignore it.

In particular from the Uccle station, we can see a great number of spikes, that will probably undermine our models.

% From the Membach station, we can see an anomalous spike at a 6-hour periodicity. 

\subsubsection{Dataset division}
As best practices suggest, we are going to divide the dataset into training and testing datasets with a ratio around $85\%/15\% - 75\%/25\%$.
Since one of our objectives is to assess any significant difference from before and after the Belgium lockdown (on March $14^{th}$ the \textit{soft} lockdown, while on March $18^{th}$ the complete lockdown), we selected data from the start of our timeseries until 20-01-2020 (64 weeks $\approx 82\%$) as training, while the test follows and ends on 27-04-2020 (14 weeks $\approx 18\%$).

This initial division demostrated to be computationally heavy while fitting some models with weekly seasonality, and we noticed a possible yearly seasonality on Uccle data (\figurename~\ref{fig:whole-data-decomposition}). Even if it is not demonstrable given the short period our data covers, applying a 24-hour MA smoothing filter on the whole dataset (546 days) and then producing the periodgram as previously done, it suggests a 8748-hours significant periodicity (364.5 days).

\begin{figure}[h]
	\centering
	\includegraphics[width=0.7\linewidth]{"project.uccs_files/figure-latex/whole data plot-2"}
	\caption{Whole Uccle data decomposition}{\footnotesize Weeks 10 and 62 include January $1^{st}~2019/2020$}
	\label{fig:whole-data-decomposition}
\end{figure}

Given those issues, we choose the training/testing sets to hold 52/18 weeks: this is the greater train-to-test ratio we deem usable ($\approx 75\%/25\%$), while maintaining computational feasibility, and we hope it will render the possible yearly seasonality less intrusive.


Some R commands cannot handle timeseries with missing values, but as we have seen both stations datasets include missing values.
Also, please note that we are going to have a timeseries object indexed by weeks, so that it contains the 168 hours between each integer index.
Since we know that the longest missing values series is 90 hours long, we can apply a simple completion strategy for serving those commands a filled timeseries: we will substitute missing values with the mean of the week they are in; in R terms \texttt{na.aggregate(x, floor)}.


\subsubsection{Decomposition}
In order to decompose our dataset into trend and seasonality(-ties) components, we followed these steps:
\begin{enumerate}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item Apply a smoothing filter to extract the trend component
	\item Remove the trend from the dataset and extract the seasonal figure using the local mean method
	\item Remove the trend and the seasonal components to obtain the residuals
\end{enumerate}
While doing so, we tested different smoothing filters: simple filter (p=seasonality), Spencer's 15-point filter and MA smoothing filter (f=seasonality). Since they do not produce particularly different seasonalities, we choose to keep the results obtained by applying the MA smoothing filter, for its significance in terms of seasonally adjusted data.


\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.uccs_files/figure-latex/extract both 24 and 168-1.pdf}
		\caption{Uccle station}
		\label{fig:decomposed:uccs}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.mems_files/figure-latex/extract both 24 and 168-1.pdf}
		\caption{Membach station}
		\label{fig:decomposed:mems}
	\end{subfigure}
	\begin{center}
		\caption{Timeseries decomposition}{\small Only the second method results are shown for clarity}
		\label{fig:decomposed}
	\end{center}
\end{figure}


Since the periodgrams suggested the presence of two significative periodicities, we also tested the extraction of both corresponding seasonalities:
\begin{enumerate}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item Apply the MA smoothing filter (f=24) on the dataset to extract the trend component
	\item Remove the trend from the dataset and extract the 24-hour seasonal figure using the local mean method
	\item Remove the 24-hour seasonal components to obtain a deseasoned dataset
	\item Apply the MA smoothing filter (f=168) on the deseasoned dataset to extract the updated trend component
	\item Remove the trend from the already deseasoned dataset and extract the 168-hour seasonal figure using the local mean method
	\item Repeat steps 1-5 using the last deseasoned dataset until convergence (2-3 cycles)
	\item Removing the last fitted trend and the two seasonalities we obtain the final residuals
\end{enumerate}

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.uccs_files/figure-latex/extract both 24 and 168-2.pdf}
		\caption{Uccle station}
		\label{fig:direct-multi-seasonality:uccs}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.mems_files/figure-latex/extract both 24 and 168-2.pdf}
		\caption{Membach station}
		\label{fig:direct-multi-seasonality:mems}
	\end{subfigure}
	\begin{center}
		\caption{Seasonality figures}{\small\textit{Direct} refers to single seasonality extraction\\\textit{Multi} refers to both seasonalities extracted at the same time}
		\label{fig:direct-multi-seasonality}
	\end{center}
\end{figure}

In \figurename~\ref{fig:direct-multi-seasonality} we see both approaches applied to both stations. Those plots show an interesting property of our seasonalities:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item Both ways of extraction result in the same daily seasonality extracted
	\item The sum of the daily and weekly seasonalities extracted together is the same as the weekly seasonality extracted directly
\end{itemize}
Given in particular the second property, we will only use the 168-hours seasonality while fitting our models, for both the stations.

In \figurename~\ref{fig:decomposed} we see the double decomposition results. While data from Uccle station have a clear significativity of both trend and seasonalities, data from Membach could seem not significant. Still, if we notice that the main timeseries lies between values of 0 and 100, we can find out that around half of the value will be composed by the trend, a 30\% by the joined seasonality components, and the remaining value by the residuals. We will need to better handle the spikes that start from the middle of that dataset.


\section{Methodology}
Having two different datasets, we need to fit two separate models that represent the two stations. During this estimation, our aim is to obtain a model that generalises our training dataset in such a way that forecasting becomes effective, also assessing errors analytically.
Obtaining such a reliable model will be the first step to verify any significant difference forecasting over the lockdown period.

The first model we are going to estimate is the ARIMA model, including the seasonality components. To identify the order of the different components described by ARIMA, we will analyse the autocorrelation and partial autocorrelation of our datasets.
As a reminder:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item non-seasonal AR process of order $p$ is described by an exponentially or sigmoidally decaying ACF, and by a cut-off of significant PACF values at lag $p$
	\item non-seasonal MA process of order $q$ is described by an exponentially or sigmoidally decaying PACF, and by a cut-off of significant ACF values at lag $q$
	\item seasonal AR process of order $P$ is described by an exponentially or sigmoidally decay at seasonal lags on ACF values, and by a cut-off of significant PACF values at each seasonal lag until the $P^{th}$
	\item seasonal MA process of order $Q$ is described by an exponentially or sigmoidally decay at seasonal lags on PACF values, and by a cut-off of significant ACF values at each seasonal lag until the $Q^{th}$
	\item given how significance is assessed for the ACF/PACF spikes, one over 20 spikes (5\%) could be \textit{coincidentally significant} or \textit{coincidentally \textbf{non}-significant}
\end{itemize}


\subsection{Uccle station}
\subsubsection{ARIMA}
Our training set, despite the precautions taken during the initial data cleanup and aggregation, does not satisfy the Normality assumption, even after applying the \textit{log} or \textit{Box-Cox} transformations. Thus, we will estimate the models using the original scale.

Since our dataset shows a relevant trend component, resulting in non-constant mean, we consider the use of the \textit{diff}\footnote{The \textit{diff} operator applies the \textit{d}-order differences, by default on lag 1. All \textit{diff} operators we will apply use $d=1$.} operator to smooth the mean.
After applying the \textit{diff} operator with lag 168, in conjunction with the lag 1 \textit{diff} or not, we come up with two possible models by checking the ACF and PACF plots:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item from using both \textit{diff}s, the ACF and PACF on the long run hint to $\mathrm{ARIMA}(0,1,0)(0,1,1)_{168}$
	\item from using just the lag 168 \textit{diff}, the PACF on the first lags and the ACF/PACF combination on the long run hint to $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$
\end{itemize}
We also employ the \textit{auto.arima} stepwise methodology\footnote{The \textit{auto.arima} stepwise methodology fits different ARIMA models within a range of orders, and based on each result's information criteria it will try to minimize it by changing each time one of the \textit{p}, \textit{d}, \textit{q}, \textit{P}, \textit{D}, or \textit{Q} values, depending on the configured limits.}, locking the \textit{diff} values to 0 or 1, to get some hints on the possible models.

Following both the analytical ways and the \textit{auto.arima} hints, and refining the models through further inspection of ACF/PACF plots of the residuals, we end up with three characteristic models. We selected them through the Akaike Information Criterion (AIC), being the only three out of the fitted models with $\mathrm{AIC} < 120.000$: $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$, $\mathrm{ARIMA}(3,1,1)(0,1,1)_{168}$, and $\mathrm{ARIMA}(4,1,2)(0,1,1)_{168}$.

Also checking the Mean Absolute Percentage Error (MAPE) on the training set, they actually have the lowest three values ($\mathrm{MAPE} < 6.2\%$). Nevertheless, MAPE is not a single valid criterion for selection, since a low error predicting the training set itself does not necessarily mean a good forecast power.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.uccs_files/figure-latex/arima-35}
		\caption{ACF and PACF plots}
		\label{fig:arima-26}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{project.uccs_files/figure-latex/arima-32}
		\caption{Q-Q plot}
		\label{fig:arima-24}
	\end{subfigure}
	\begin{center}
		\caption{Plots for $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$}
		\label{fig:arima}
	\end{center}
\end{figure}

The ACF and PACF of the residuals for all three models are very similar (\figurename~\ref{fig:arima-26}), even if the models themselves have great differences in meaning and in number of parameters: they highlight a clear seasonal ARMA process with periodicity 24. This shows how our previous conclusion that the 168 hours seasonality could include the 24 hours one is flawed. Unfortunately, the parameters estimator we are using does not permit to estimate multiple seasonalities\footnote{\textit{Arima} method from the \textit{forecast} R package, only specifying the seasonal and non-seasonal orders.}.

Probably related to the 24 hours periodicity that remains on the residuals, together with the non-Normality of the original data, all Q-Q plots show clear divergence on both sides of the distribution (\figurename~\ref{fig:arima-24}). The Box-Pierce test statistics accept the independence hypothesis between residuals.

Then, we assess how the forecasts behave on the test set. The MAPE for all three models more than doubles to around 17\% for $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$ and around 15\% for the other two. This is expected, since normally the model is more fitted to the training data than to unknown future data. Also, it must be noted that a January $1^{st}$ period lies in our test dataset, and without being able to include a yearly seasonality, that leads to greater errors just from those couple of weeks (\figurename~\ref{fig:arima-forecast:200011}).

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=1\linewidth]{project.uccs_files/figure-latex/arima-37}
		\caption{$\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$}
		\label{fig:arima-forecast:200011}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=1\linewidth]{project.uccs_files/figure-latex/arima-69}
		\caption{$\mathrm{ARIMA}(3,1,1)(0,1,1)_{168}$}
		\label{fig:arima-forecast:412011}
	\end{subfigure}
	\begin{center}
		\caption{ARIMA forecasts}{\footnotesize$\mathrm{ARIMA}(4,1,2)(0,1,1)_{168}$ behaves like $\mathrm{ARIMA}(3,1,1)(0,1,1)_{168}$ with faster increasing variablity}
		\label{fig:arima-forecast}
	\end{center}
\end{figure}

We can see in \figurename~\ref{fig:arima-forecast} the forecast behaviour for our models. We can appreciate the constant span of the confidence intervals in \figurename~\ref{fig:arima-forecast:200011}, in constrast with the more complex models that have increasing intervals further away from the training set. It must be noted that the increasing intervals include negative values, that are actually impossible to obtain given the data meaning (difference between maximum and minimum measurements).

The increasing variability also make the percentage of test values falling inside the confidence intervals to be higher than normal:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$: $\approx81\%$ of data is in the $80\%$ CI and $\approx91\%$ in the $95\%$ CI
	\item $\mathrm{ARIMA}(3,1,1)(0,1,1)_{168}$: $\approx96\%$ of data is in the $80\%$ CI and $\approx98\%$ in the $95\%$ CI
	\item $\mathrm{ARIMA}(4,1,2)(0,1,1)_{168}$: $\approx98\%$ of data is in the $80\%$ CI and $\approx99\%$ in the $95\%$ CI
\end{itemize}

Also, ARIMA parameters roots have values within the unit circle for the first two models, while for $\mathrm{ARIMA}(4,1,2)(0,1,1)_{168}$ two of the roots fall outside the unit circle, with values of $\approx1.49$ and $\approx1.80$.

Given all these factors, we are confident choosing the $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$ model, being aware of the missed 24 hours seasonality.

%\subsubsection{MSTL}
%\subsubsection{Fourier}

\subsection{Membach station}
\subsubsection{ARIMA}
Similarly to data from Uccle, data from Membach doesn't respect the Normality assumption. We tested if the Q-Q plot showed significantly better approximation of the Normal distribution after applying the \textit{log} or \textit{Box-Cox} transformations, and the latter makes the data approach Normality with $\lambda\approx-1$ (\figurename~\ref{fig:mems:box-cox}). This solves the high peaks problem we already noticed while decomposing to highlight the trend and seasonalities.

Since the $\lambda$ value approximately simplifies the Box-Cox transformation formula from $(y^\lambda-1)/\lambda$ into $(y-1)/y$, and since we only have positive values, all transformed values fall into the higher $0-1$ spectrum, in particular $0.95-1$ (\figurename~\ref{fig:mems:box-cox:data}). This will probably cause some approximation errors that could rig the final results.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=1\linewidth]{"project.mems_files/figure-latex/training data transformation plots-7"}
		\caption{Transformed training set}
		\label{fig:mems:box-cox:data}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=1\linewidth]{"project.mems_files/figure-latex/training data transformation plots-9"}
		\caption{Normal vs. transformed data distribution}
		\label{fig:mems:box-cox:qq}
	\end{subfigure}
	\begin{center}
		\caption{Results of Box-Cox transformation}
		\label{fig:mems:box-cox}
	\end{center}
\end{figure}

The transformed data still shows no constant mean, even if it has a way better shape than the original data, confirmed by the Q-Q plot (\figurename~\ref{fig:mems:box-cox:qq}). Thus, we consider the usage of the \textit{diff} operator, at lag 1 and 168. Interestingly, the analysis of ACF and PACF plots hints to similar models to the Uccle station:
$\mathrm{ARIMA}(0,1,0)(0,1,1)_{168}$ and $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$.

In this case, the employment of \textit{auto.arima} stepwise methodology does not lead to any useful model, since it obtains $\mathrm{AICc}=\inf$ for the two manually-chosen models, that have an AICc value around -84.500, while the best model found by that methodology has an AICc around -81.000. This can be caused by approximation errors\footnote{The \textit{auto.arima} methodology was only used with initial approximation, due to high computing time.}, as we supposed earlier.

The analysis of ACF/PACF plots of the residuals from both models do not lead to any new model but, as with the Uccle station, we can notice a clear 24 hours periodicity.

Both models have valid p-value results for the Box-Pierce test, similar AICc values, and similar MAPE on the training set. Thus, we can assess the forecasts for both models in \figurename~\ref{fig:mems:arima}.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=1\linewidth]{"project.mems_files/figure-latex/arima-21"}
		\caption{$\mathrm{ARIMA}(0,1,1)(0,1,1)_{168}$}
		\label{fig:mems:arima:011011}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=1\linewidth]{"project.mems_files/figure-latex/arima-13"}
		\caption{$\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$}
		\label{fig:mems:arima:200011}
	\end{subfigure}
	\begin{center}
		\caption{ARIMA forecasts}
		\label{fig:mems:arima}
	\end{center}
\end{figure}

The first model catches a rapidly-increasing trend, while the latter predicts more stable values moving the most part of the increasing trend into increasing variability. Visually, both could be acceptable, even if the latter seems to better behave on \textit{normal} days losing precision on high-valued ones, while the first tries to better accomodate the high-valued days losing precision on the \textit{normal} ones.

Analytically, we have quite a difference between the two models in terms of adherence of the confidence intervals:
\begin{itemize}[topsep=0.5em,itemsep=0em,partopsep=0.5em]
	\item $\mathrm{ARIMA}(0,1,1)(0,1,1)_{168}$: $\approx98\%$ of data is in the $80\%$ CI and $\approx99\%$ in the $95\%$ CI
	\item $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$: $\approx73\%$ of data is in the $80\%$ CI and $\approx89\%$ in the $95\%$ CI
\end{itemize}
As we see, the first model over-generalises the variability, while the latter seems more precise, even if losing some information. Also considering the MAPE on the test set, the latter model fits the data better with a $16\%$ error, instead of the $18\%$ for the first model.

Parameters roots for both models have values within the unit circle.

Thus, we can select the $\mathrm{ARIMA}(2,0,0)(0,1,1)_{168}$ model on the Box-Cox($\lambda\approx-1$) transformed data, still being aware of the missed 24 hours seasonality, similarly to the Uccle station.

%\subsubsection{MSTL}

\subsection{Lockdown influence}
Even if the two models have the same order, they cannot be directly compared using the Information Criteria, for the Membach model works after a transformation pass, and they are fitted from different data.

\subsubsection{Seasonalities divergence}
We can still compare how the seasonalities differ with respect with each original dataset and between each other, by extracting the seasonalities for each station from before and after the lockdown (March $14^{th}$).

We will highlight the confidence bands for an estimated error of 67\%. This interval estimation lies on the assumption that values for each single hour in the hourly/weekly seasonality is Normally distributed, a slightly different assumption that is not necessarily refuted by the already seen Q-Q plots.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.uccs_files/figure-latex/seasonalities/before-after-compare-1"}
		\caption{Uccle station}
		\label{fig:season.lockdown:uccs}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.mems_files/figure-latex/seasonalities/before-after-compare-1"}
		\caption{Membach station}
		\label{fig:season.lockdown:mems}
	\end{subfigure}
	\begin{center}
		\caption{Seasonalities computed before and after the lockdown}{\small Seasonalities extracted together, confidence bands $\pm\mathrm{sd}$}
		\label{fig:season.lockdown}
	\end{center}
\end{figure}


As we can see in \figurename~\ref{fig:season.lockdown}, the seasonalities' shapes seem different, in particular comparing the weekly seasonality. The seasonalities from before and after the lockdown are still included in the highlighted confidence bands, apart from a few hours. This is true for both stations.

\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.mems_files/figure-latex/seasonalities/seasonplot-mean-sd-1"}
		\caption{Before lockdown}
		\label{fig:season.lockdown:msb:mems}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.mems_files/figure-latex/seasonalities/seasonplot-mean-sd-2"}
		\caption{After lockdown}
		\label{fig:season.lockdown:msa:mems}
	\end{subfigure}
	\begin{center}
		\caption{Seasonal plots for Membach station}
		\label{fig:season.lockdown:ms:mems}
	\end{center}
\end{figure}

The differences in shape are more highlighted checking the seasonal plots \cite{hyndman2018forecasting} in \figurename~\ref{fig:season.lockdown:ms:mems}. It is possible to notice a couple of changes: the Monday to Friday shapes are heavily flattened almost on the weekend values, and all the values are flattened towards 0. Both flattenings can be noticed checking the Uccle station, not showed for brevity.

\subsubsection{Forecast divergence}
\begin{figure}[h]
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.uccs_files/figure-latex/final-model-7"}
		\caption{Uccle station}
		\label{fig:forecast.lockdown:uccs}
	\end{subfigure}
	\begin{subfigure}{.5\linewidth}
		\includegraphics[width=\linewidth]{"project.mems_files/figure-latex/final-model-7"}
		\caption{Membach station}
		\label{fig:forecast.lockdown:mems}
	\end{subfigure}
	\begin{center}
		\caption{Forecasts from March $2^{nd}$.}{\small In red the actual values, in black the forecasts. March $14^{th}$ at midnight is highlighted.}
		\label{fig:forecast.lockdown}
	\end{center}
\end{figure}

By fitting the model\footnote{Data is different, because we are fitting the model on the original train+test dataset, but if we follow similar steps for both stations we can see that the final model we shall choose is the same. Also, the $\lambda$ parameter for the Box-Cox transformation of Membach data is estimated equally.} on data until March $1^{st}$ we can compute forecasts for 8 weeks ahead, until April $26^{th}$. As we can see in \figurename~\ref{fig:forecast.lockdown}, both stations overestimate starting after the lockdown. Uccle data in particular show a greater overestimation that can be noticed also by looking at the difference between the forecasted and measured values.

Analytically, the MAPE for Uccle doubles with respect to the previous test set ($\approx34\%$), and only 58\% and 78\% of the test data falls inside the confidence intevals (80\% and 95\%). Analysing the Membach station, we find those measures have comparable values to the previous test set: the MAPE remains at $16.6\%$, while 74\% and 90\% of data falls inside the confidence intervals.

%MEMS
%Test set inside the CI
%80% CI 	  74.18 %
%95% CI 	  89.58 %
%Errors:  forecast with ARIMA(2,0,0)(0,1,1)[168] 
%MSE= 117.9258   MAE= 7.709243   MAPE= 16.60103   RMSE= 10.85937   R2= 0.4777765 


%UCCS
%Test set inside the CI
%80% CI 	  57.51 %
%95% CI 	  78.42 %
%Errors:  forecast with ARIMA(2,0,0)(0,1,1)[168] 
%MSE= 670897.8   MAE= 664.5903   MAPE= 33.94793   RMSE= 819.0835   R2= 0.5188538 


%Uccle: remodel on 52+18 (until 1st March 2020), forecast 2 months (8 weeks) => diff in MAPE
%Membach: remodel on 52+18 (until 1st March 2020), forecast 2 months (8 weeks) => diff in MAPE

\section{Conclusions}
\subsubsection{Lockdown influence}
\subsection{Limitations and future works}
The main problems of this projects that we identified are multiple seasonalities and the Normality assumption.

The tested models do not effectively include both daily and weekly seasonalities, even if initially we thought so. Also they cannot include the apparent yearly seasonality, mainly because of the short timeseries.
To overcome this limitation, we could try different models, also ARIMA-based, that can estimate multiple seasonalities. The first that we tested models seasonalites through Fourier terms. The main problem that lead us not to go further with that approach is that our seasonalities cannot be expressed by a combination of few sine and cosine curves. This requires a high number of curves to estimate, that requires an heavy computational power.

To compensate those difficulties, in the literature it is suggested to test TBATS models, which combines Fourier terms, Box-Cox transformation, and exponential smoothing. This seems a suitable approach given the analyses we performed until now, that can possibly address the non-Normal distribution.

The final suggestion for future work would be to better analyse the differences between stations, in such a way to better correlate different influences of the lockdown on the areas near each station.




\newpage
\bibliography{project}

\end{document}
