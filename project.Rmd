
```{r "libraries", include=FALSE}
library(knitr)
opts_chunk$set(warning = F, message = F)
library(stringi) # %s+%
library(lubridate) # floor_date
library(xts) # zoo
library(fpp) # auto.arima
library(ggplot2)
library(ggrepel) # for nicer labels on ggplot
# library(gridExtra) # for gg-plotting multiple plots
library(cowplot) # for plot_grid
# library(car) # qqPlot
library(qqplotr) # qqplot with ggplot
library(spec) # for periodgram
library(tidyverse) # map_df, read_csv, group_by, summarize...
library(tsbox) # https://cran.r-project.org/web/packages/tsbox/vignettes/tsbox.html
```


```{r "initial setup", include=FALSE}
print_dec <- function(x, decimals=2) trimws(format(round(x, decimals), nsmall=decimals))

setwd("/media/data/Documents/Uni/spatiotemp/villalobos/project/")
if (exists("proj_file") & file.exists(proj_file)) {
  load(proj_file)
  # save.image(proj_file)
}

gg_qqplot <- function(dataset) {
  if (is.ts(dataset))
    dataset <- as.numeric(dataset)
  ggplot(data.frame(values=dataset), aes(sample=values)) +
    stat_qq_band() + stat_qq_line(col="red") + stat_qq_point(shape = 1, size = 3) +
    xlab("Theoretical quantiles (95% conf.)")
}
```

```{r "import dataset", include=FALSE}
seis <-
  list.files(path="csv/", pattern=pattern) %>%
  map_df(~read_csv("csv/" %s+% .))

```



# Data preparation
```{r "dataset description", echo=FALSE}
long_description <- description %s+% " (" %s+% name %s+% " station)"
cat(long_description, "\n")
cat("Domain values:", domain[1], "to", domain[2], "nm\n")
cat("Data from", format.POSIXct(min(seis$utc_second), "%Y-%m-%d %H:%M:%S"), "to", format.POSIXct(max(seis$utc_second), "%Y-%m-%d %H:%M:%S"), "\n")
```

```{r cleanup, echo=FALSE}
out_domain <- (seis$min < domain[1] | seis$max > domain[2])
invalid_values <- (seis$min == -1 & seis$max == 1) | (seis$min == 0 & seis$max == 0) | out_domain
cat("Removing", sum(out_domain), "values out of domain,", (sum(invalid_values) - sum(out_domain)), "explicit NA\n")
seis <-
  seis %>%
  mutate(min=replace(min, invalid_values, NA), max=replace(max, invalid_values, NA)) %>%
  drop_na()
# %>% mutate(belgian_second=with_tz(utc_second, "Europe/Brussels"))
remove(out_domain, invalid_values) # free ~350 Mb from RAM
```
## Missing values analysis (seconds)
```{r missing values analysis}
seis.complete <- seis %>% complete(utc_second=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = as.difftime("0:0:1")))
seis.first.second <- min(seis$utc_second)
seis.missing.ids <- which(is.na(seis.complete$min))
#seis.complete$utc_second[seis.missing.ids]
seis.present <- length(seis$utc_second)
seis.total <- length(seis.complete$utc_second)
seis.missing <- seis.total - seis.present
cat(seis.present, "present values,", seis.missing, "missing points (", print_dec(seis.present / seis.total * 100, 2), "% /", print_dec(seis.missing / seis.total * 100, 2), "% )\n")

block_start <- NULL
block_end <- NULL
blocks <- data.frame(start=integer(), end=integer())
for (i in 1:length(seis.missing.ids)) {
  if (is.null(block_start)) {
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  } else if ((block_end + 1) == seis.missing.ids[i]) {
    block_end <- seis.missing.ids[i]
  } else {
    blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  }
}
blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
blocks$interval <- seconds(blocks$end - blocks$start + 1)
blocks$start <- seis.first.second + seconds(blocks$start + 1)
blocks$end <- seis.first.second + seconds(blocks$end + 1)
plot(blocks$start, blocks$interval,
     col=ifelse(blocks$interval<3600, "darkgreen", "darkred"),
     main="Consecutive seconds of missing values",
     ylab="Seconds", xlab="Interval start (mm-'yy)",
     xaxt="n", xlim=c(min(seis$utc_second), max(seis$utc_second))
)
axis.POSIXct(1, at=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = "1 month"), format="%m-'%y", cex=0.8)
abline(h=3600, col="green", lty="dotted")
legend("topleft", legend=c("interval >= 1h", "interval < 1h", "1h"), col=c("darkred", "darkgreen", "green"), lty=c(NA,NA,3), pch=c(1,1,NA),cex=0.9, bty="n")
text(x=blocks$start[which(blocks$interval > 3600)], y=blocks$interval[which(blocks$interval > 3600)], labels = paste0(blocks$start[which(blocks$interval > 3600)], " - ", blocks$end[which(blocks$interval > 3600)]), cex=0.9, pos=4)
remove(seis.complete, seis.missing.ids, seis.present, seis.total, seis.missing, block_start, block_end, blocks)
```


```{r gc_post_missing_analysis, include=FALSE}
gc()
```

```{r group by hour, include=FALSE}
bruxelles <- function(d) with_tz(d, "Europe/Brussels")
force_bruxelles <- function(d) force_tz(d, "Europe/Brussels")
force_utc <- function(d) force_tz(d, "UTC")

seis.h <- 
  seis %>%
  # mutate(utc_hour=as_datetime(date(utc_second)) + hour(utc_second) * 3600) %>% # this forces the hour to represent bruxelles local time in utc. tz-ed time is normally evaluated in utc by ts-related functions
  group_by(utc_hour=floor_date(force_utc(bruxelles(utc_second)), "1 hour")) %>%
  summarize(mean_movement_s=mean(max-min)) # %>%
#  complete(utc_hour=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = as.difftime("1:0:0")))

seis.before <- 
  seis.h[which(is.na(force_bruxelles(seis.h$utc_hour) + hours(1))), ] %>%
  mutate(utc_hour=utc_hour + hours(1))

seis.after <- 
  seis.h[which(is.na(force_bruxelles(seis.h$utc_hour) - hours(1))), ] %>%
  mutate(utc_hour=utc_hour - hours(1))

seis.dst.fix <-
  merge(seis.before, seis.after, all=T) %>%
  group_by(utc_hour=utc_hour) %>%
  summarize(mean_movement_s=mean(mean_movement_s))

seis.h <- merge(seis.h, seis.dst.fix, all=T)
remove(seis.after, seis.before, seis.dst.fix)

# invalid_values <- seis.h$mean_movement_s > 200
# seis.h <-
#   seis.h %>%
#   mutate(mean_movement_s=replace(mean_movement_s, invalid_values, NA)) %>%
#   drop_na()
# remove(invalid_values)

gc()
```

## Missing values analysis (hours)
```{r missing values hour analysis}
seis.complete <- seis.h %>% complete(utc_hour=seq.POSIXt(from=min(seis.h$utc_hour), to=max(seis.h$utc_hour), by = as.difftime("1:0:0")))
seis.first.second <- min(seis$utc_second)
seis.missing.ids <- which(is.na(seis.complete$mean_movement_s))
# seis.complete$utc_hour[seis.missing.ids]
seis.present <- length(seis.h$utc_hour)
seis.total <- length(seis.complete$utc_hour)
seis.missing <- seis.total - seis.present
cat(seis.present, "present values,", seis.missing, "missing points (", print_dec(seis.present / seis.total * 100, 2), "% /", print_dec(seis.missing / seis.total * 100, 2), "% )\n")

block_start <- NULL
block_end <- NULL
blocks <- data.frame(start=integer(), end=integer())
for (i in 1:length(seis.missing.ids)) {
  if (is.null(block_start)) {
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  } else if ((block_end + 1) == seis.missing.ids[i]) {
    block_end <- seis.missing.ids[i]
  } else {
    blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
    block_start <- seis.missing.ids[i]
    block_end <- seis.missing.ids[i]
  }
}
blocks[nrow(blocks) + 1, ] <- c(block_start, block_end)
blocks$interval <- hours(blocks$end - blocks$start + 1)
blocks$start <- seis.first.second + hours(blocks$start + 1)
blocks$end <- seis.first.second + hours(blocks$end + 1)
plot(c(rbind(blocks$start, blocks$end, NA)), rep(hour(blocks$interval), each=3),
     col=ifelse(blocks$interval<3600, "darkgreen", "darkred"),
     main="Consecutive hours of missing values",
     ylab="Hours", xlab="Interval start (mm-'yy)",
     type="l", lwd=10,
     xaxt="n", xlim=c(min(seis$utc_second), max(seis$utc_second))
     )
axis.POSIXct(1, at=seq.POSIXt(from=min(seis$utc_second), to=max(seis$utc_second), by = "1 month"), format="%m-'%y", cex=0.8)
text(x=blocks$start, y=hour(blocks$interval) - .2, labels = paste0(format(blocks$start, "%y-%m-%d %H:%M")), cex=0.9, pos=2)
# text(x=blocks$end, y=hour(blocks$interval), labels = paste0(format(blocks$end, "%y-%m-%d %H:%M")), cex=0.9, pos=4)
text(x=blocks$end, y=hour(blocks$interval) - .2, labels = paste0(hour(blocks$interval), "H"), cex=0.9, pos=4)
#text(x=blocks$start + make_difftime(hour=sapply(hour(blocks$interval), "/", y=2)), y=hour(blocks$interval), labels = paste0(hour(blocks$interval), "H"), cex=0.9, pos=3)
#text(x=blocks$start + make_difftime(hour=sapply(hour(blocks$interval), "/", y=2)), y=hour(blocks$interval), labels = paste0(hour(blocks$interval), "H"), cex=0.9, pos=1)
blocks$start
blocks$interval
remove(seis.complete, seis.missing.ids, seis.present, seis.total, seis.missing, block_start, block_end, blocks)

```

```{r gc_post_missing_analysis_bru, include=FALSE}
gc()
```


```{r build_ts function, include=FALSE}
build_ts <- function(dset, periods=NULL, start=NULL, end=NULL, force_ms=T) {
  dset.ts <- ts_zoo(dset)
  if (!is.null(start) | !is.null(end)) {
    dset.ts <- ts_span(dset.ts, start=start, end=end)
  }
  dset.ts <- ts_regular(dset.ts)
  if (is.null(periods)) {
    return(dset.ts)
  }
  if (is.vector(periods) & length(periods) == 1) {
    periods <- periods[1]
  }
  if (is.integer(periods)){
    if (force_ms) {
      periods <- c(periods)
    } else {
      frequency(dset.ts) <- periods
      return(dset.ts)
    }
  }
  return(msts(dset.ts, periods))
}
```



```{r test_train split ts, include=FALSE}
data.lab <- "Hourly mean (nm)"

seis.h.start <- as_datetime('2018-10-29T00:00:00')
seis.h.end <- as_datetime('2020-03-02T00:00:00') - seconds(1)
seasonality.period <- 24
seasonality.xlab <- "Days"
seasonality.aggregate <- function(ds) na.aggregate(ds, function(x) floor(x/14))
seasonality.period <- 168
seasonality.xlab <- "Weeks"
seasonality.aggregate <- function(ds) na.aggregate(ds, floor)
seis.h.ts <- build_ts(seis.h, periods = c(seasonality.period), start = seis.h.start, end = seis.h.end, force_ms = T)

seis.test.split <- seis.h.start + days(52*7)

seis.train.start <- seis.h.start
seis.train.end <- seis.test.split - seconds(1)
seis.h.train <- build_ts(seis.h, periods = c(seasonality.period), start = seis.train.start, end = seis.train.end, force_ms = T)

seis.test.start <- seis.test.split
seis.test.end <- seis.test.start + days(7*18) - seconds(1)
seis.h.test <- build_ts(seis.h, periods = c(seasonality.period), start = seis.train.start, end = seis.test.end, force_ms = T)
seis.h.test <- window(seis.h.test, start = c(end(seis.h.train)[1] + 1, 1))
seis.test.length <- length(seis.h.test)
```

# Analysis
```{r whole data plot}
month.starts <- seq.POSIXt(from=floor_date(seis.h.start, 'month'), to=ceiling_date(seis.h.end, 'month'), by = "1 month")
hours.from.start <- as.numeric(month.starts-seis.h.start)*24+168
autoplot(seis.h.ts, type="l") +
  scale_x_continuous(breaks=hours.from.start/168, labels=format(month.starts, "%m-%y")) +
  ylab(data.lab) + xlab(NULL) + labs(title = "Training set", caption = "Data in original scale")
week.starts <- seq.POSIXt(from=floor_date(seis.h.start, 'week'), to=ceiling_date(seis.h.end, 'week'), by = "1 week")
hours.from.start <- as.numeric(week.starts-seis.h.start)*24+168
autoplot(seis.h.ts, type="l") +
  scale_x_continuous(breaks=hours.from.start/168, labels=format(week.starts, "%d-%m-%y"), limits = c(11,15)-3/24) +
  scale_y_continuous(limits = c(min(seis.h.ts[(10*168):(16*168)]), max(seis.h.ts[(10*168):(16*168)]))) +
  ylab(data.lab) + xlab(NULL) + labs(title = "Training set", subtitle = "4-weeks zoom", caption = "Data in original scale")
dec.addi <- decompose(seasonality.aggregate(seis.h.ts))
autoplot(dec.addi) + labs(title="Decomposition of additive time series", subtitle = paste0("Seasonality ", seasonality.period)) + xlab("Weeks")
```

```{r training data transformation plots}
month.starts <- seq.POSIXt(from=floor_date(seis.train.start, 'month'), to=ceiling_date(seis.train.end, 'month'), by = "1 month")
hours.from.train.start <- as.numeric(month.starts-seis.train.start)*24+168

autoplot(seis.h.train, type="l") +
  scale_x_continuous(breaks=hours.from.train.start/168, labels=format(month.starts, "%m-%y")) +
  ylab(data.lab) + xlab(NULL) + ggtitle("Training set") + labs(caption = "Data in original scale")
gghistogram(seis.h.train, add.normal = T) + xlab(data.lab) + labs(caption = "Data in original scale")
gg_qqplot(seis.h.train) + 
  labs(title="Q-Q plot for training dataset") + ylab("Sample quantiles") + labs(caption = "Data in original scale")

autoplot(log(seis.h.train), type="l") +
  scale_x_continuous(breaks=hours.from.train.start/168, labels=format(month.starts, "%m-%y")) +
  ylab(data.lab) + xlab(NULL) + ggtitle("Training set") + labs(caption = "Data in log-scale")
gghistogram(log(seis.h.train), add.normal = T) + xlab(data.lab) + labs(caption = "Data in log-scale")
gg_qqplot(log(seis.h.train)) + 
  labs(title="Q-Q plot for training dataset") + ylab("Sample quantiles") + labs(caption = "Data in log-scale")

train.bc.lambda <- BoxCox.lambda(seis.h.train)
train.bc <- BoxCox(seis.h.train, train.bc.lambda)
autoplot(train.bc, type="l") +
  scale_x_continuous(breaks=hours.from.train.start/168, labels=format(month.starts, "%m-%y")) +
  ylab(data.lab) + xlab(NULL) + ggtitle("Training set") + labs(caption = paste0("Data Box-Cox transformed with lambda = ", train.bc.lambda))
gghistogram(train.bc, add.normal = T) + xlab(data.lab) + labs(caption = paste0("Data Box-Cox transformed with lambda = ", train.bc.lambda))
gg_qqplot(train.bc) + 
  labs(title="Q-Q plot for training dataset") + ylab("Sample quantiles") + labs(caption = paste0("Data Box-Cox transformed with lambda = ", train.bc.lambda))
```

## Periodgram
```{r periodgram}
min_h_seasonality <- 24
min_h_seasonality <- 2
pgram <- spec.pgram(stats::filter(build_ts(seis.h, start = seis.train.start, end = seis.train.end), side=2, filter=c(0.5, rep(1,min_h_seasonality-1), 0.5)/min_h_seasonality),
#`pgram <- spec.pgram(build_ts(seis.h, start = seis.train.start, end = seis.train.end),
                    detrend=F, demean=T, na.action=na.aggregate, plot=F)
pgram.data <- data.frame(freq=pgram$freq, spec=pgram$spec)
ggplot(pgram.data) +
  geom_line(aes(freq, spec)) +
  xlab("frequency") + ylab("power level") +
  labs(title = paste("Periodgram -", description), caption = paste0("bandwidth = ", pgram$bandwidth, "    df = ", pgram$df)) ->
  periodgram

start_ratio <- 3
filter_freq <- (pgram$spec > (mean(pgram$spec) + sd(pgram$spec)*start_ratio)) & 1/pgram$freq/3600 < 24*365
top95pc <- pgram$spec[filter_freq]
top95freq <- pgram$freq[filter_freq][order(top95pc, decreasing = T)]
top95pc <- pgram$spec[filter_freq][order(top95pc, decreasing = T)]
cat("SD ratio\n")
(top95pc - mean(pgram$spec))/sd(pgram$spec)
top95seas.s <- 1/top95freq
cat("Raw frequency by unit\n")
top95seas.s
top95seas.h <- top95seas.s/3600
cat("Frequency by unit\n")
top95seas.h

ratio.color <- function(x) ifelse(x >= (mean(pgram$spec) + sd(pgram$spec)*3), "red", ifelse(x >= (mean(pgram$spec) + sd(pgram$spec)*2), "blue", ifelse(x >= (mean(pgram$spec) + sd(pgram$spec)*1), "darkgreen", "orange")))
shown_labels <- 4
periodgram +
  scale_x_continuous(sec.axis = sec_axis(~1/./3600, breaks=c(1, 3, 2*c(1,2,3,4,6,12), 24*7), labels = as.integer, name="hours")) +
  scale_y_continuous(n.breaks=6) +
  #scale_y_continuous(sec.axis = sec_axis(~., breaks=mean(pgram$spec) + sd(pgram$spec) * c(start_ratio:3), labels=c("1", "2", "3")[c(start_ratio:3)])) +
  geom_hline(yintercept=(mean(pgram$spec) + sd(pgram$spec) * c(start_ratio:3)), linetype="dotted", color = ratio.color(mean(pgram$spec) + sd(pgram$spec) * c(start_ratio:3))) +
  geom_point(data=data.frame(freq=top95freq, spec=top95pc), aes(freq, (spec), color=ratio.color(spec)), shape="o", size=4, show.legend = F) +
  geom_label_repel(data=data.frame(freq=top95freq, spec=top95pc)[1:shown_labels,], aes(freq, (spec), label=round(1/freq/3600), color=ratio.color(spec)), segment.color="grey", show.legend=F) +
  scale_color_manual(values = c("darkgreen", "blue", "red")[start_ratio:3])

remove(pgram, pgram.data, filter_freq, top95pc, top95freq, top95seas.s, top95seas.h, ratio.color, periodgram)
gc()
```

## Decomposition

```{r plot data with (p)acf}
seis.h.24 <- build_ts(seis.h.train, periods = c(24))
seasonplot(seis.h.24, type="l", col=rainbow(7))
legend("topleft", legend=weekdays(seis.train.start + (as.difftime(c(0:6), units="days"))), col=rainbow(7), lty=1, cex=0.8)
remove(seis.h.24)

plot_grid(
  autoplot(seis.h.train, main = "Hourly seismic movement", xlab = seasonality.xlab, ylab = "mean movement (nm)"),
  gghistogram(seis.h.train, add.normal = T) + xlab("mean movement (nm)"),
  nrow = 2)
plot_grid(
  autoplot(acf(seis.h.train, na.action=na.pass, plot=F, lag.max=seasonality.period)) + scale_x_continuous(),
  autoplot(pacf(seis.h.train, na.action=na.pass, plot=F, lag.max=seasonality.period)) + scale_x_continuous(),
  nrow = 2)
```
Once notice the composition is additive (the fluctuations does not seem to grow with the trend)

```{r decompose}
dec.addi <- decompose(seasonality.aggregate(seis.h.train))
autoplot(dec.addi) + labs(title="Decomposition of additive time series", subtitle = paste0("Seasonality ", seasonality.period))
dec.multi <- decompose(log(seasonality.aggregate(seis.h.train)))
autoplot(dec.multi) + labs(title="Decomposition of multiplicative time series (log-scale additive)", subtitle = paste0("Seasonality ", seasonality.period))
dec.multi.plain <- decompose(seasonality.aggregate(seis.h.train), type="multip")
autoplot(dec.multi.plain) + labs(title="Decomposition of multiplicative time series", subtitle = paste0("Seasonality ", seasonality.period))
plot_grid(
  autoplot(acf(dec.addi$random, na.action=na.omit, plot=F)) + scale_x_continuous(),
  autoplot(acf(dec.multi$random, na.action=na.omit, plot=F)) + scale_x_continuous(),
  autoplot(acf(dec.multi.plain$random, na.action=na.omit, plot=F)) + scale_x_continuous(),
  nrow = 3)
plot_grid(
  autoplot(pacf(dec.addi$random, na.action=na.omit, plot=F)) + scale_x_continuous(),
  autoplot(pacf(dec.multi$random, na.action=na.omit, plot=F)) + scale_x_continuous(),
  autoplot(pacf(dec.multi.plain$random, na.action=na.omit, plot=F)) + scale_x_continuous(),
  nrow = 3)
```

### Manual filtering/decomposition
We now extract the trend using a linear filter with smoothing parameter $p$ equal to 180 (almost half a year):

```{r linear trend}
p <- floor(seasonality.period/2)
weights <- rep(1/(2*p+1), times=2*p+1)
trend <- stats::filter(seasonality.aggregate(seis.h.train), sides=2, filter = weights)
```


```{r show_overlap_and_diff, include=FALSE}
show_overlap_and_diff <- function(base, compare, base.desc, compare.desc, xlab, overlap.ylab, diff.title, diff.ylab, diff.ylab.sec, diff.ylab.sec.accuracy=.1) {
  overlap_plot <-
    autoplot(compare, xlab=xlab, ylab=overlap.ylab) +
      geom_line(aes(y=base, col="red"), show.legend = F) +
      labs(title=NULL, subtitle=paste0(base.desc, " vs ", compare.desc))
  diff <- compare-base

  mse <- mean(diff^2, na.rm = T)
  mae <- mean(abs(diff), na.rm = T)
  mape <- mean(abs(diff/base) * 100, na.rm = T)
  rmse <- sqrt(mse)
  R2 <- 1-(sum((diff)^2, na.rm = T)/sum((base-mean(base))^2, na.rm = T))
  cat("Errors: ", compare.desc, "\n")
  cat("\t","MSE=", mse, "  MAE=", mae, "  MAPE=", mape, "  RMSE=", rmse, "  R2=", R2, "\n")
  
  span <- max(compare, base, na.rm = T) - min(compare, base, na.rm = T)
  accu.lims <- diff.ylab.sec.accuracy / 100 * span * c(-3,3)
  diff_plot <-
    autoplot(diff, ylab = paste0("Difference (", diff.ylab, ")"), xlab = xlab) +
      expand_limits(y=accu.lims) +
      labs(title = diff.title, subtitle = paste0(base.desc, " - ", compare.desc)) +
      scale_y_continuous(sec.axis = sec_axis(~./span, name=paste0("Difference (", diff.ylab.sec, ")"), labels = scales::percent_format(accuracy = diff.ylab.sec.accuracy))) +
      geom_hline(yintercept=mean(diff, na.rm=T), linetype="dashed", color = "red")
  return(list(overlap_plot, diff_plot))
}
```


And they match:
```{r linear trend plot}
plots <- show_overlap_and_diff(
  dec.addi$trend, trend, xlab=seasonality.xlab,
  base.desc = "additive decomposition trend",
  compare.desc = paste0("linear filtered trend with p=", p),
  overlap.ylab = "Trend (nm)",
  diff.title = "Difference between trends",
  diff.ylab = "nm", diff.ylab.sec="% over trend span"
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)

```

Then we use a filter able also to capture some seasonal effect so we will be able to find the residuals. We are going to choose $f=365$ so to have the moving average from the first day of the year to the last one and then shifted from the second day of the year to the first one of the following year and so, this is because we believe to have an yearly seasonality.

```{r trend Spencer}
weights.s <- c(-3,-6,-5,3,21,46,67)
weights.s <- c(weights.s, 74, rev(weights.s))
weights.s <- weights.s/sum(weights.s)
trend.s <- stats::filter(seasonality.aggregate(seis.h.train), side=2, filter=weights.s)

plots <- show_overlap_and_diff(
  dec.addi$trend, trend.s, xlab=seasonality.xlab,
  base.desc = "additive decomposition trend",
  compare.desc = "Spencer's 15-point MA",
  overlap.ylab = "Trend (nm)",
  diff.title = "Difference between trends",
  diff.ylab = "nm", diff.ylab.sec="% over trend span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)


```

```{r trend MA}
f <- seasonality.period
weights.s <- c(0.5, rep(1,f-1), 0.5)/f
trend.s <- stats::filter(seasonality.aggregate(seis.h.train), side=2, filter=weights.s)

plots <- show_overlap_and_diff(
  dec.addi$trend, trend.s, xlab=seasonality.xlab,
  base.desc = "additive decomposition trend",
  compare.desc = paste0("shift-filtered trend with f=", f),
  overlap.ylab = "Trend (nm)",
  diff.title = "Difference between trends",
  diff.ylab = "nm", diff.ylab.sec="% over trend span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)


```

and they match (with some error of course) with the ones found with the decompose function.

Finally we want to prove we can retrieve seasonality, in order to do so we can compute the average seasonality starting from the detrended series: to do so we put the time series into a matrix and we transform this matrix so each column contains elements of the same period and finally, we compute the mean of each column. We will check this with the element figure of the object decomposition i.e. the estimated seasonal figure not repeated for all the time series. 

```{r trend figure}
detrended <- seasonality.aggregate(seis.h.train)-trend.s
detrended <- window(detrended, end = c(end(detrended)[1], seasonality.period), extend=T)
matrix <- t(matrix(data = detrended, nrow = seasonality.period))
seasonality.figure <- as.ts(colMeans(matrix, na.rm = T))
seasonality <- rep(seasonality.figure, length(detrended)/length(seasonality.figure))[1:length(trend.s)]
```

and they almost match: 

```{r difference of trend figure}

plots <- show_overlap_and_diff(
  dec.addi$figure, seasonality.figure, xlab=seasonality.xlab,
  base.desc = "additive decomposition",
  compare.desc = paste0("mean-over-period after removal of shift-filtered trend with f=", f),
  overlap.ylab = "Seasonality (nm)",
  diff.title = paste0("Difference between seasonalities (f=", seasonality.period, ")"),
  diff.ylab = "nm", diff.ylab.sec="% over seasonality span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)

# difference is maybe given by na.aggregate used in decompose, while na.rm=T in manual seasonality?
```

```{r residuals}
residuals <- seasonality.aggregate(seis.h.train) - trend.s - seasonality

plots <- show_overlap_and_diff(
  dec.addi$random, residuals, xlab=seasonality.xlab,
  base.desc = "additive decomposition",
  compare.desc = paste0("mean-over-period after removal of shift-filtered trend with f=", f),
  overlap.ylab = "Residuals (nm)",
  diff.title = paste0("Difference between residuals (f=", seasonality.period, ")"),
  diff.ylab = "nm", diff.ylab.sec="% over residuals span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)

residuals.acf <- autoplot(acf(residuals, na.action = na.pass, plot=F)) + scale_x_continuous()
residuals.pacf <- autoplot(pacf(residuals, na.action = na.pass, plot=F)) + scale_x_continuous()
plot_grid(residuals.acf, residuals.pacf, nrow=2)


```

In fact we are able to reconstruct the original series, with of course some missing value at the beginning and at the end because of the methods applied previously:

```{r difference of reconstruct}
ts <- residuals+trend.s+seasonality

plots <- show_overlap_and_diff(
  seis.h.train, ts, xlab=seasonality.xlab,
  base.desc = "original series",
  compare.desc = "reconstructed serie (manual)",
  overlap.ylab = data.lab,
  diff.title = "Difference between ts",
  diff.ylab = "nm", diff.ylab.sec="% over ts span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)

plots <- show_overlap_and_diff(
  seis.h.train, dec.addi$trend+dec.addi$seasonal+dec.addi$random, xlab=seasonality.xlab,
  base.desc = "original series",
  compare.desc = "reconstructed serie (decompose additive)",
  overlap.ylab = data.lab,
  diff.title = "Difference between ts",
  diff.ylab = "nm", diff.ylab.sec="% over ts span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)

```


```{r cleanup seasonalities}
remove(matrix, weights, weights.s, ts)
gc()
```

### Multi trend extraction

```{r extract both 24 and 168}
trend.s_compute <- function(ts.in, period) {
  f <- period
  weights.s <- c(0.5, rep(1,f-1), 0.5)/f
  trend.s <- stats::filter(ts.in, side=2, filter=weights.s)
  return(trend.s)
}

season_by_mean <- function(ts.in, period) {
  freq <- frequency(ts.in)
  if (freq == period) {
    end <- c(end(ts.in)[1], period)
  } else {
    end <- c(((end(ts.in)[1] * freq) %/% period + 1) * (period/freq), freq)
  }
  extended <- window(ts.in, end = end, extend=T)
  matrix <- t(matrix(data = extended, nrow = period))
  seasonality.figure <- as.ts(colMeans(matrix, na.rm = T))
  seasonality.sd <- as.ts(apply(matrix, 2, sd, na.rm = T))
  seasonality <- rep(seasonality.figure, length(extended)/length(seasonality.figure))[1:length(ts.in)]
  return(list(figure=seasonality.figure, seasonal=seasonality, sd=seasonality.sd))
}

trend_season <- function(ts.in, period) {
  trend.s <- trend.s_compute(ts.in, period)
  season <- season_by_mean(ts.in-trend.s, period)
  season$trend <- trend.s
  return(season)
}
  
aggregated <- seasonality.aggregate(seis.h.train)
season.24 <- trend_season(aggregated, 24)
season.168 <- trend_season(aggregated-season.24$seasonal, 168)

season.24 <- trend_season(aggregated-season.168$seasonal, 24)
season.168 <- trend_season(aggregated-season.24$seasonal, 168)

# this third iteration isn't actually needed
season.24 <- trend_season(aggregated-season.168$seasonal, 24)
season.168 <- trend_season(aggregated-season.24$seasonal, 168)

plot_grid(
  autoplot(aggregated) + labs(title="Timeseries", cex=0.7) + ylab("") + xlab("") + theme(plot.margin=margin(b=-6, unit="pt")),
  autoplot(ts(season.24$figure, frequency=1)) + labs(title="Daily seasonality", cex=0.7) + ylab("") + xlab("") + theme(plot.margin=margin(r=10, b=-6, unit="pt")),
  autoplot(ts(season.168$trend, frequency=168)) + labs(title="Trend", cex=0.7) + ylab("") + xlab("") + theme(plot.margin=margin(l=4, b=-6, unit="pt")),
  autoplot(ts(season.168$figure, frequency=1)) + labs(title="Weekly seasonality", cex=0.7) + ylab("") + xlab("") + theme(plot.margin=margin(r=10, b=-6, unit="pt")),
  autoplot(aggregated-season.24$seasonal-season.168$seasonal-season.168$trend) + labs(title="Residuals", cex=0.7) + ylab("") + xlab("") + theme(plot.margin=margin(t=-6, b=-6, unit="pt")),
  autoplot(season.168$figure + rep(season.24$figure, 7)) + labs(title="Composed seasonality", cex=0.7) + ylab("") + xlab("") + theme(plot.margin=margin(r=10, b=-6, unit="pt")),
  nrow = 3,
  greedy = T)


seasonbase.24 <- trend_season(aggregated, 24)
seasonbase.168 <- trend_season(aggregated, 168)

plot_grid(
  autoplot(ts(seasonbase.24$figure, frequency=1)) + ylab("") + xlab("Hours") + scale_x_continuous() + geom_line(aes(col="Direct daily"), size=1.5) +
    geom_line(aes(y=season.24$figure, col="Multi daily")) +
    scale_colour_manual("", values=c("purple", "yellow"), breaks=c("Direct daily", "Multi daily")),
  autoplot(ts(seasonbase.168$figure, frequency=1)) + ylab("") + xlab("Hours") + scale_x_continuous() + geom_line(aes(col="Direct weekly"), size=1.5) +
    geom_line(aes(y=season.168$figure + rep(season.24$figure, 7), col="Multi w+d")) +
    #geom_line(aes(y=rep(seasonbase.24$figure, 7), col="Direct daily"), size=1.5) +
    #geom_line(aes(y=rep(season.24$figure, 7), col="Multi daily")) +
    geom_line(aes(y=season.168$figure, col="Multi weekly")) +
    scale_colour_manual("", values=c("red", "purple", "blue", "yellow", "green"), breaks=c("Direct weekly", "Direct daily", "Multi" %s+% c(" weekly", " daily", " w+d"))),
  nrow = 2)


plots <- show_overlap_and_diff(
  seasonbase.168$figure, season.168$figure + rep(season.24$figure, 7), xlab="Hours",
  base.desc = "168 from ds",
  compare.desc = "168+24 from ds",
  overlap.ylab = data.lab,
  diff.title = "Difference between 168",
  diff.ylab = "nm", diff.ylab.sec="% over season span",
  diff.ylab.sec.accuracy = .01
)
plot_grid(plots[[1]], plots[[2]], nrow = 2)

remove(aggregated)

```





# Forecast

```{r diffs acf/pacf}
seis.h.train %>% ggtsdisplay(lag.max = 168*4)
seis.h.train %>% diff() %>% ggtsdisplay(lag.max = 168*4)
# seis.h.train %>% diff(D=2) %>% ggtsdisplay(lag.max = 168)
# seis.h.train %>% diff(lag=24) %>% ggtsdisplay(lag.max = 168)
# seis.h.train %>% diff() %>% diff(lag=24) %>% ggtsdisplay(lag.max = 24, main="Supposed model: ARIMA(24,1,0)(0,1,2)[24]") # ARIMA(0,1,0)(0,1,2)[24]
# previous => ARIMA(5,1,0)(0,1,7)[24]
# seis.h.train %>% diff() %>% diff(lag=24, D=2) %>% ggtsdisplay(lag.max = 168)
seis.h.train %>% diff(lag=168) %>% ggtsdisplay(lag.max = 168*4) # arima (0,0,0)(0,1,1/2)[168]
# acf variable and partially sinusoidal, pacf shows peaks each 168
seis.h.train %>% diff() %>% diff(lag=168) %>% ggtsdisplay(lag.max = 168*4) # arima (0,1,0)(0,1,1)[168]
seis.h.train %>% diff() %>% diff(lag=168) %>% ggtsdisplay(lag.max = 172) # arima (0,1,0)(0,1,1)[168]
# acf cuts off after p=168, pacf shows peaks each 168   
# seis.h.train %>% diff() %>% diff(lag=168, D=2) %>% ggtsdisplay(lag.max = 168)
seis.h.train %>% diff() %>% diff(lag=24) %>% diff(lag=168) %>% ggtsdisplay(lag.max = 168*4)
```

```{r diffs/d168-acf-pacf}
plot_grid(
  seis.h.train %>% diff(lag=168) %>%  acf(lag.max = 24,    plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  seis.h.train %>% diff(lag=168) %>%  acf(lag.max = 168*4, plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  seis.h.train %>% diff(lag=168) %>% pacf(lag.max = 24,    plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  seis.h.train %>% diff(lag=168) %>% pacf(lag.max = 168*4, plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  nrow = 2
)
```

```{r diffs/d-d168-acf-pacf}
plot_grid(
  seis.h.train %>% diff() %>% diff(lag=168) %>%  acf(lag.max = 24,    plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  seis.h.train %>% diff() %>% diff(lag=168) %>%  acf(lag.max = 168*4, plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  seis.h.train %>% diff() %>% diff(lag=168) %>% pacf(lag.max = 24,    plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  seis.h.train %>% diff() %>% diff(lag=168) %>% pacf(lag.max = 168*4, plot = F, na.action = na.pass) %>% autoplot() + labs(title = NULL) + scale_x_continuous(),
  nrow = 2
)
```

```{r plot_forecast func}
plot_forecast <- function(forec) {
  BP <- Box.test(forec$model$residuals, type="Box-Pierce")
  autoplot(forec) +
    labs(title=forec$method, subtitle = paste0("Box-Pierce p-value=", print_dec(BP$p.value, decimals=4))) +
    autolayer(forec$mean, series="Forecast") -> plotted
  return(plotted)
}
```


